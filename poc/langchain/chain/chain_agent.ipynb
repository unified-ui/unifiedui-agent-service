{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d16098",
   "metadata": {},
   "source": [
    "# LangChain ReAct Agent mit Azure OpenAI\n",
    "\n",
    "Dieses Notebook zeigt, wie man einen einfachen ReAct Agent mit LangChain und Azure OpenAI baut, der streamt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b16e5730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation (falls nötig)\n",
    "# !pip install langchain langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6190bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6a7fd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44665d",
   "metadata": {},
   "source": [
    "## 1. Azure OpenAI Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86a833e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI Konfiguration\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\", \"your-api-key\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"https://your-resource.openai.azure.com/\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-15-preview\")\n",
    "\n",
    "# LLM initialisieren\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    streaming=True,  # Für Streaming-Unterstützung\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]  # Live-Output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4ef8234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello — how can I help you today?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello — how can I help you today?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-5-mini-2025-08-07', 'model_provider': 'openai'}, id='lc_run--019b9282-a345-7f42-bfdd-3f8a8c264ff9', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 7, 'output_tokens': 19, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c9266",
   "metadata": {},
   "source": [
    "## 2. Einfache Tools definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd156da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Führt einfache mathematische Berechnungen aus.\n",
    "    \n",
    "    Args:\n",
    "        expression: Eine mathematische Expression wie \"2 + 3 * 4\"\n",
    "        \n",
    "    Returns:\n",
    "        Das Ergebnis der Berechnung als String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Sicherheitscheck - nur erlaubte Operationen\n",
    "        allowed_chars = set(\"0123456789+-*/(). \")\n",
    "        if not all(c in allowed_chars for c in expression):\n",
    "            return \"Fehler: Nur Zahlen und Grundrechenarten (+, -, *, /) erlaubt\"\n",
    "        \n",
    "        result = eval(expression)\n",
    "        return f\"Ergebnis: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Fehler bei der Berechnung: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Simuliert eine Web-Suche (für Demo-Zwecke).\n",
    "    \n",
    "    Args:\n",
    "        query: Suchbegriff\n",
    "        \n",
    "    Returns:\n",
    "        Simuliertes Suchergebnis\n",
    "    \"\"\"\n",
    "    # In der Realität würde hier eine echte Such-API verwendet werden\n",
    "    mock_results = {\n",
    "        \"wetter berlin\": \"Das Wetter in Berlin ist sonnig, 22°C\",\n",
    "        \"python tutorial\": \"Python ist eine Programmiersprache. Besuchen Sie python.org für Tutorials\",\n",
    "        \"langchain\": \"LangChain ist ein Framework für LLM-Anwendungen\"\n",
    "    }\n",
    "    \n",
    "    for key, result in mock_results.items():\n",
    "        if key in query.lower():\n",
    "            return f\"Suchergebnis für '{query}': {result}\"\n",
    "    \n",
    "    return f\"Keine Ergebnisse gefunden für: {query}\"\n",
    "\n",
    "# Tools-Liste\n",
    "tools = [calculator, search_web]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344722f",
   "metadata": {},
   "source": [
    "## 3. ReAct Agent erstellen\n",
    "\n",
    "LangChain bietet vorgefertigte Klassen für ReAct Agents:\n",
    "- `create_agent`: Erstellt einen ReAct Agent mit vorgefertigtem Prompt\n",
    "- Agent ist direkt verwendbar (Runnable) - kein AgentExecutor mehr nötig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d1965ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct Agent Template (vereinfacht)\n",
    "react_template = \"\"\"Du bist ein hilfreicher AI-Assistent. Verwende die folgenden Tools, um Fragen zu beantworten.\n",
    "\n",
    "Verfügbare Tools:\n",
    "{tools}\n",
    "\n",
    "Verwende das folgende Format:\n",
    "Question: die Eingabe-Frage\n",
    "Thought: denke Schritt für Schritt\n",
    "Action: das Tool, das du verwenden möchtest, mit Input\n",
    "Observation: das Ergebnis des Tools\n",
    "... (dieses Thought/Action/Observation kann sich wiederholen)\n",
    "Final Answer: die finale Antwort\n",
    "\n",
    "Beginne!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(react_template)\n",
    "\n",
    "# Agent erstellen\n",
    "agent = create_agent(llm, tools)\n",
    "\n",
    "# Agent ist jetzt direkt verwendbar (kein AgentExecutor mehr nötig)\n",
    "# In LangChain 1.x sind Agents Runnable und können direkt verwendet werden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70d0d3",
   "metadata": {},
   "source": [
    "## 4. Agent testen (ohne Streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9498b255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nach Punkt-vor-Strich: zuerst 27 × 3 = 81, dann 15 + 81 = 96.Finale Antwort:\n",
      "Nach Punkt-vor-Strich: zuerst 27 × 3 = 81, dann 15 + 81 = 96.\n"
     ]
    }
   ],
   "source": [
    "# Einfacher Test ohne Streaming\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Was ist 15 + 27 mal 3?\"}]\n",
    "})\n",
    "\n",
    "print(\"Finale Antwort:\")\n",
    "try:\n",
    "    # Some runtimes return message objects with attribute access\n",
    "    print(result['messages'][-1].content)\n",
    "except Exception:\n",
    "    # Fallback for dict-like messages\n",
    "    print(result['messages'][-1].get('content', result['messages'][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161938e",
   "metadata": {},
   "source": [
    "## 5. Agent mit Streaming\n",
    "\n",
    "Für Streaming verwenden wir die `astream_events` Methode des Agent direkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd29a6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frage: Berechne 42 * 7 und suche nach 'python tutorial'\n",
      "==================================================\n",
      "\n",
      "Using tool: search_web\n",
      "Tool result: content=\"Suchergebnis für 'python tutorial': Python ist eine Programmiersprache. Besuchen Sie python.org für Tutorials\" name='search_web' tool_call_id='call_hKrYmAEATRwuKhdYVSsPafhc'\n",
      "\n",
      "Using tool: calculator\n",
      "Tool result: content='Ergebnis: 294' name='calculator' tool_call_id='call_asiNx0CdVyoI0Igdp42hBea4'\n",
      "DasDas Ergebnis Ergebnis der der Rechnung Rechnung::  4242 × ×  77 = =  294294.\n",
      "\n",
      ".\n",
      "\n",
      "SuchSucherergebnisgebnis für für \" \"pythonpython tutorial tutorial\":\": Python Python ist ist eine eine Program Programmimierserspracheprache.. Bes Besuchenuchen Sie Sie python python.org.org für für Tutorials Tutorials.\n",
      "\n",
      ".\n",
      "\n",
      "SollSoll ich ich Ihnen Ihnen konkrete konkrete Ein Einsteigersteiger‑‑ oder oder Fort Fortgeschgeschrittenrittenenen‑‑RRessessourcenourcen//LinksLinks zusammen zusammenstellenstellen??"
     ]
    }
   ],
   "source": [
    "# Streaming-Funktion\n",
    "async def run_agent_streaming(query: str):\n",
    "    \"\"\"Führt den Agent mit Streaming aus\"\"\"\n",
    "    print(f\"Frage: {query}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    async for event in agent.astream_events(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "        version=\"v1\"\n",
    "    ):\n",
    "        kind = event[\"event\"]\n",
    "        if kind == \"on_chain_start\":\n",
    "            if event[\"name\"] == \"Agent\":\n",
    "                print(f\"Starting agent: {event['name']}\")\n",
    "        elif kind == \"on_chain_end\":\n",
    "            if event[\"name\"] == \"Agent\":\n",
    "                print(f\"Done agent: {event['name']}\")\n",
    "        elif kind == \"on_chat_model_stream\":\n",
    "            content = event[\"data\"][\"chunk\"].content\n",
    "            print(content, end=\"\", flush=True)\n",
    "        elif kind == \"on_tool_start\":\n",
    "            print(f\"\\nUsing tool: {event['name']}\")\n",
    "        elif kind == \"on_tool_end\":\n",
    "            print(f\"Tool result: {event['data']['output']}\")\n",
    "\n",
    "# Beispiel mit Streaming\n",
    "await run_agent_streaming(\"Berechne 42 * 7 und suche nach 'python tutorial'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06dd979",
   "metadata": {},
   "source": [
    "## 6. Einfacher Chat-Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_loop():\n",
    "    \"\"\"Einfacher Chat-Loop für Interaktion\"\"\"\n",
    "    print(\"ReAct Agent Chat (type 'quit' to exit)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"Du: \")\n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            break\n",
    "            \n",
    "        await run_agent_streaming(user_input)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Chat starten (kommentiert aus, da input() in Notebook problematisch ist)\n",
    "# await chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ecba8",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "**Vorgefertigte Klassen in LangChain:**\n",
    "- `create_agent()`: Erstellt ReAct Agent automatisch\n",
    "- Agent ist Runnable - direkte Verwendung mit `.invoke()`, `.stream()`, `.astream_events()`\n",
    "- Streaming über `astream_events()`\n",
    "\n",
    "**Azure OpenAI Integration:**\n",
    "- `AzureChatOpenAI` Klasse für Azure Endpoints\n",
    "- Automatische Streaming-Unterstützung\n",
    "- Callbacks für Live-Output\n",
    "\n",
    "**Tools:**\n",
    "- Einfach mit `@tool` Decorator definierbar\n",
    "- Automatische Schema-Generierung für LLM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
