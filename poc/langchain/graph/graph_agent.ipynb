{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff457e64",
   "metadata": {},
   "source": [
    "# LangGraph ReAct Agent mit Azure OpenAI\n",
    "\n",
    "Dieses Notebook zeigt, wie man einen einfachen ReAct Agent mit LangGraph und Azure OpenAI baut, der streamt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e421311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation (falls n√∂tig)\n",
    "# !pip install langgraph langchain langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e6a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.graph import START, END\n",
    "from langchain.tools import tool\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8652e4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14889673",
   "metadata": {},
   "source": [
    "## 1. Azure OpenAI Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4451b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI Konfiguration\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\", \"your-api-key\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"https://your-resource.openai.azure.com/\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-15-preview\")\n",
    "\n",
    "# LLM initialisieren\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    temperature=0.7,\n",
    "    streaming=True,  # F√ºr Streaming-Unterst√ºtzung\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]  # Live-Output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c72882",
   "metadata": {},
   "source": [
    "## 2. Einfache Tools definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f37635b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"F√ºhrt einfache mathematische Berechnungen aus.\n",
    "    \n",
    "    Args:\n",
    "        expression: Eine mathematische Expression wie \"2 + 3 * 4\"\n",
    "        \n",
    "    Returns:\n",
    "        Das Ergebnis der Berechnung als String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Sicherheitscheck - nur erlaubte Operationen\n",
    "        allowed_chars = set(\"0123456789+-*/(). \")\n",
    "        if not all(c in allowed_chars for c in expression):\n",
    "            return \"Fehler: Nur Zahlen und Grundrechenarten (+, -, *, /) erlaubt\"\n",
    "        \n",
    "        result = eval(expression)\n",
    "        return f\"Ergebnis: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Fehler bei der Berechnung: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Simuliert eine Web-Suche (f√ºr Demo-Zwecke).\n",
    "    \n",
    "    Args:\n",
    "        query: Suchbegriff\n",
    "        \n",
    "    Returns:\n",
    "        Simuliertes Suchergebnis\n",
    "    \"\"\"\n",
    "    # In der Realit√§t w√ºrde hier eine echte Such-API verwendet werden\n",
    "    mock_results = {\n",
    "        \"wetter berlin\": \"Das Wetter in Berlin ist sonnig, 22¬∞C\",\n",
    "        \"python tutorial\": \"Python ist eine Programmiersprache. Besuchen Sie python.org f√ºr Tutorials\",\n",
    "        \"langchain\": \"LangChain ist ein Framework f√ºr LLM-Anwendungen\",\n",
    "        \"langgraph\": \"LangGraph ist ein Framework f√ºr agentische Workflows mit Graph-Struktur\"\n",
    "    }\n",
    "    \n",
    "    for key, result in mock_results.items():\n",
    "        if key in query.lower():\n",
    "            return f\"Suchergebnis f√ºr '{query}': {result}\"\n",
    "    \n",
    "    return f\"Keine Ergebnisse gefunden f√ºr: {query}\"\n",
    "\n",
    "# Tools-Liste\n",
    "tools = [calculator, search_web]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066636d1",
   "metadata": {},
   "source": [
    "### ReAct Agent erstellen\n",
    "\n",
    "Im folgenden Abschnitt erstellen wir einen ReAct-Agenten mit LangChain/ LangGraph. Verwende `create_agent` statt des √§lteren `create_react_agent`-Helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5623e31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Structure:\n",
      "        +-----------+         \n",
      "        | __start__ |         \n",
      "        +-----------+         \n",
      "               *              \n",
      "               *              \n",
      "               *              \n",
      "          +-------+           \n",
      "          | model |           \n",
      "          +-------+.          \n",
      "          .         .         \n",
      "        ..           ..       \n",
      "       .               .      \n",
      "+---------+         +-------+ \n",
      "| __end__ |         | tools | \n",
      "+---------+         +-------+ \n"
     ]
    }
   ],
   "source": [
    "# ReAct Agent mit LangGraph erstellen\n",
    "# Dies erstellt automatisch einen vollst√§ndigen Graph mit:\n",
    "# - State Management\n",
    "# - Tool-Calling\n",
    "# - ReAct Logik\n",
    "# - Streaming-Unterst√ºtzung\n",
    "\n",
    "app = create_agent(llm, tools)\n",
    "\n",
    "# Graph visualisieren (optional)\n",
    "print(\"Graph Structure:\")\n",
    "print(app.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4bdb1",
   "metadata": {},
   "source": [
    "## 4. Agent testen (ohne Streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a833773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Ergebnis von 15 + 27 mal 3 ist 96.Finale Antwort:\n",
      "Das Ergebnis von 15 + 27 mal 3 ist 96.\n"
     ]
    }
   ],
   "source": [
    "# Einfacher Test ohne Streaming\n",
    "result = app.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Was ist 15 + 27 mal 3?\"}]\n",
    "})\n",
    "\n",
    "print(\"Finale Antwort:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25285d89",
   "metadata": {},
   "source": [
    "## 5. Agent mit Streaming\n",
    "\n",
    "LangGraph bietet integrierte Streaming-Unterst√ºtzung √ºber `astream()` und `astream_events()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90806a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frage: Berechne 42 * 7 und suche nach 'langgraph'\n",
      "==================================================\n",
      "\n",
      "üîß Using tool: search_web\n",
      "\n",
      "üîß Using tool: calculator\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ToolMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Tool result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m100\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Beispiel mit Streaming\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_agent_streaming(\u001b[33m\"\u001b[39m\u001b[33mBerechne 42 * 7 und suche nach \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlanggraph\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mrun_agent_streaming\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müîß Using tool: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m kind == \u001b[33m\"\u001b[39m\u001b[33mon_tool_end\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Tool result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moutput\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'ToolMessage' object is not subscriptable"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Ergebnis der Berechnung von 42 * 7 ist 294. \n",
      "\n",
      "Zur Suche nach \"langgraph\": LangGraph ist ein Framework f√ºr agentische Workflows mit Graph-Struktur. Wenn du mehr Details m√∂chtest, kann ich gerne weiter helfen."
     ]
    }
   ],
   "source": [
    "# Streaming-Funktion\n",
    "async def run_agent_streaming(query: str):\n",
    "    \"\"\"F√ºhrt den Agent mit Streaming aus\"\"\"\n",
    "    print(f\"Frage: {query}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    async for event in app.astream_events(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "        version=\"v1\"\n",
    "    ):\n",
    "        kind = event[\"event\"]\n",
    "        if kind == \"on_chat_model_stream\":\n",
    "            content = event[\"data\"][\"chunk\"].content\n",
    "            if content:\n",
    "                print(content, end=\"\", flush=True)\n",
    "        elif kind == \"on_tool_start\":\n",
    "            print(f\"\\nüîß Using tool: {event['name']}\")\n",
    "        elif kind == \"on_tool_end\":\n",
    "            print(f\"‚úÖ Tool result: {event['data']['output'][:100]}...\")\n",
    "\n",
    "# Beispiel mit Streaming\n",
    "await run_agent_streaming(\"Berechne 42 * 7 und suche nach 'langgraph'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d7f07",
   "metadata": {},
   "source": [
    "## 6. Detailliertes Streaming mit Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400626de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frage: Was ist 10 + 5?\n",
      "============================================================\n",
      "Event: on_chain_start\n",
      "  Chain: LangGraph\n",
      "----------------------------------------\n",
      "Event: on_chain_start\n",
      "  Chain: model\n",
      "----------------------------------------\n",
      "Event: on_chat_model_start\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_stream\n",
      "----------------------------------------\n",
      "Event: on_chat_model_end\n",
      "----------------------------------------\n",
      "Event: on_chain_stream\n",
      "----------------------------------------\n",
      "Event: on_chain_end\n",
      "  Chain End: model\n",
      "----------------------------------------\n",
      "Event: on_chain_stream\n",
      "----------------------------------------\n",
      "Event: on_chain_start\n",
      "  Chain: tools\n",
      "----------------------------------------\n",
      "Event: on_tool_start\n",
      "  Tool: calculator\n",
      "  Input: {'expression': '10 + 5'}\n",
      "----------------------------------------\n",
      "Event: on_tool_end\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ToolMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Detailliertes Beispiel\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_agent_detailed_streaming(\u001b[33m\"\u001b[39m\u001b[33mWas ist 10 + 5?\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mrun_agent_detailed_streaming\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33minput\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m kind == \u001b[33m\"\u001b[39m\u001b[33mon_tool_end\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Tool Result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moutput\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m kind == \u001b[33m\"\u001b[39m\u001b[33mon_chain_start\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Chain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'ToolMessage' object is not subscriptable"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 + 5 ergibt 15."
     ]
    }
   ],
   "source": [
    "async def run_agent_detailed_streaming(query: str):\n",
    "    \"\"\"Zeigt alle Streaming-Events detailliert\"\"\"\n",
    "    print(f\"Frage: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    async for event in app.astream_events(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "        version=\"v1\"\n",
    "    ):\n",
    "        kind = event[\"event\"]\n",
    "        print(f\"Event: {kind}\")\n",
    "        \n",
    "        if kind == \"on_chat_model_stream\":\n",
    "            content = event[\"data\"][\"chunk\"].content\n",
    "            if content:\n",
    "                print(f\"  Content: {repr(content)}\")\n",
    "        elif kind == \"on_tool_start\":\n",
    "            print(f\"  Tool: {event['name']}\")\n",
    "            print(f\"  Input: {event['data']['input']}\")\n",
    "        elif kind == \"on_tool_end\":\n",
    "            print(f\"  Tool Result: {event['data']['output'][:50]}...\")\n",
    "        elif kind == \"on_chain_start\":\n",
    "            print(f\"  Chain: {event['name']}\")\n",
    "        elif kind == \"on_chain_end\":\n",
    "            print(f\"  Chain End: {event['name']}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Detailliertes Beispiel\n",
    "await run_agent_detailed_streaming(\"Was ist 10 + 5?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedabf38",
   "metadata": {},
   "source": [
    "## 7. State-Streaming (nur finale Updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5afeaefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frage: Erkl√§re kurz was LangGraph ist\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m30\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# State-Streaming Beispiel\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_agent_state_streaming(\u001b[33m\"\u001b[39m\u001b[33mErkl√§re kurz was LangGraph ist\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mrun_agent_state_streaming\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m app.astream(\n\u001b[32m      7\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: query}]}\n\u001b[32m      8\u001b[39m ):\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Zeigt nur die neueste Nachricht\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m     11\u001b[39m         latest_msg = state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m]\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(latest_msg, \u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m latest_msg.content:\n",
      "\u001b[31mKeyError\u001b[39m: 'messages'"
     ]
    }
   ],
   "source": [
    "async def run_agent_state_streaming(query: str):\n",
    "    \"\"\"Streamt nur die finalen State-Updates\"\"\"\n",
    "    print(f\"Frage: {query}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    async for state in app.astream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": query}]}\n",
    "    ):\n",
    "        # Zeigt nur die neueste Nachricht\n",
    "        if state[\"messages\"]:\n",
    "            latest_msg = state[\"messages\"][-1]\n",
    "            if hasattr(latest_msg, 'content') and latest_msg.content:\n",
    "                print(f\"State Update: {latest_msg.content[:100]}...\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# State-Streaming Beispiel\n",
    "await run_agent_state_streaming(\"Erkl√§re kurz was LangGraph ist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0113f68",
   "metadata": {},
   "source": [
    "## 8. Einfacher Chat-Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b432a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_loop():\n",
    "    \"\"\"Einfacher Chat-Loop f√ºr Interaktion\"\"\"\n",
    "    print(\"LangGraph ReAct Agent Chat (type 'quit' to exit)\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"Du: \")\n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            break\n",
    "            \n",
    "        await run_agent_streaming(user_input)\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Chat starten (kommentiert aus, da input() in Notebook problematisch ist)\n",
    "# await chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a96d7",
   "metadata": {},
   "source": [
    "## 9. Custom Graph (f√ºr erweiterte Anwendungsf√§lle)\n",
    "\n",
    "Wenn du mehr Kontrolle brauchst, kannst du auch einen eigenen Graph bauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f6954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Custom State (erweitert MessagesState)\n",
    "class AgentState(MessagesState):\n",
    "    pass\n",
    "\n",
    "# Tool Node\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Agent Node\n",
    "def agent_node(state: AgentState):\n",
    "    \"\"\"Agent denkt und entscheidet √ºber Tool-Nutzung\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.bind_tools(tools).invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Bedingung f√ºr Tool-Nutzung\n",
    "def should_use_tools(state: AgentState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "# Custom Graph bauen\n",
    "custom_graph = StateGraph(AgentState)\n",
    "custom_graph.add_node(\"agent\", agent_node)\n",
    "custom_graph.add_node(\"tools\", tool_node)\n",
    "custom_graph.add_edge(START, \"agent\")\n",
    "custom_graph.add_conditional_edges(\"agent\", should_use_tools)\n",
    "custom_graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "custom_app = custom_graph.compile()\n",
    "\n",
    "# Custom Graph testen\n",
    "result = custom_app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Was ist 25 * 4?\")]\n",
    "})\n",
    "\n",
    "print(\"Custom Graph Result:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d20fde",
   "metadata": {},
   "source": [
    "In fr√ºheren Versionen wurde `create_react_agent()` verwendet. Aktuell nutze `create_agent()` und √ºbergebe das LLM sowie die Tools. Der Agent unterst√ºtzt Streaming und State-Graph-Visualisierung."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
